---
tags:
  - theory
---

# Lecture 1

## Information Theory

!!! definition "Shannon's Entropy"
    If $X$ is a random variable over a set of events $\{x\}$ such that event $x$ occurs with probability $p_x$, then the Shannon entropy of event $x$ is given by:

    $$
        -\log_2(p_x).
    $$

信息的擦除是不可逆过程，每擦除 1 bit 信息，环境的熵就增加 $k_B \ln 2$.

## Computational Complexity

![pE19FgA.png](https://s21.ax1x.com/2025/02/24/pE19FgA.png)
